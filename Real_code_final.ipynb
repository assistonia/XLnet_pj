{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import AdamW, get_scheduler\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = [\n",
    "    \"Company\", \"EducationalInstitution\", \"Artist\", \"Athlete\", \"OfficeHolder\", \"MeanOfTransportation\",\n",
    "    \"Building\", \"NaturalPlace\", \"Village\", \"Animal\", \"Plant\", \"Album\", \"Film\", \"WrittenWork\"\n",
    "]\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"dbpedia_14\")\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"content\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"content\", \"title\"])\n",
    "\n",
    "# Use the entire dataset for training, validation, and testing\n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_test_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "# Create a validation set from the training set\n",
    "val_size = int(0.1 * len(full_train_dataset))  # 10% for validation\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "full_train_dataset, full_val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# Data collator for padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/pyongjoo/anaconda3/envs/cuda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataLoader settings\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(full_train_dataset, shuffle=True, batch_size=batch_size, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(full_val_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(full_test_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "\n",
    "# Load model\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=len(class_labels))\n",
    "\n",
    "# Optimizer settings\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Scheduler settings\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f3f164b5c2435a9e49cea94ae2a5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9933\n",
      "Validation Error Rate: 0.0067\n",
      "Test Accuracy: 0.9929\n",
      "Test Error Rate: 0.0071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Validation and Test Evaluation\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\", \"labels\"]}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            y_true.extend(batch['labels'].cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_true_val, y_pred_val = evaluate_model(model, val_dataloader)\n",
    "val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
    "val_precision = precision_score(y_true_val, y_pred_val, average='weighted')\n",
    "val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
    "val_f1 = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "val_error = 1 - val_accuracy\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Error Rate: {val_error:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_true_test, y_pred_test = evaluate_model(model, test_dataloader)\n",
    "test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "test_precision = precision_score(y_true_test, y_pred_test, average='weighted')\n",
    "test_recall = recall_score(y_true_test, y_pred_test, average='weighted')\n",
    "test_f1 = f1_score(y_true_test, y_pred_test, average='weighted')\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Error Rate: {test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label: Film, Predicted Label: Film\n",
      "True Label: NaturalPlace, Predicted Label: NaturalPlace\n",
      "True Label: EducationalInstitution, Predicted Label: EducationalInstitution\n",
      "True Label: Album, Predicted Label: Album\n",
      "True Label: Artist, Predicted Label: Artist\n",
      "True Label: Album, Predicted Label: Album\n",
      "True Label: Artist, Predicted Label: Artist\n",
      "True Label: EducationalInstitution, Predicted Label: EducationalInstitution\n",
      "True Label: EducationalInstitution, Predicted Label: EducationalInstitution\n",
      "True Label: Album, Predicted Label: Album\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Random sample prediction\n",
    "subset_size = 1000  # Define the subset size\n",
    "random_test_indices = random.sample(range(len(full_test_dataset)), subset_size)\n",
    "random_test_dataset = full_test_dataset.select(random_test_indices)\n",
    "random_test_dataloader = DataLoader(random_test_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "\n",
    "# Evaluate on random sample\n",
    "y_true_random, y_pred_random = evaluate_model(model, random_test_dataloader)\n",
    "for true_label, pred_label in zip(y_true_random[:10], y_pred_random[:10]):\n",
    "    print(f\"True Label: {class_labels[true_label]}, Predicted Label: {class_labels[pred_label]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
